# A.R.G.U.S. – Dual‑Mode Laser‑Targeting Drone System

**Author**: Soham Amit Shah  
**Discipline**: Mechanical Engineering, Year 1  
**Project Focus**: Computer Vision · Gesture Interfaces · Embedded UAV Control

---

## Overview

**A.R.G.U.S.** (Aerial Reconnaissance & Guided UAV Shooter) is a custom-built, dual-mode drone-mounted laser targeting system featuring:

- **Autonomous Mode** – Balloon detection via YOLOv8 on Raspberry Pi, with target-centered laser aiming using a tilt servo and drone yaw control via Pixhawk.
- **Manual (Gesture) Mode** – Wireless ESP32-based gloves recognize hand gestures to trigger laser actions (aim, shoot, kill).
- **Mode Switching** – Modes can be toggled externally, and the system has built-in safety via a kill-switch gesture.

---

## Project Structure

```
argus-laser-targeting/
├── models/
│   ├── argus_model.pt              # Trained YOLOv8 weights
│   └── training datasets/          # Balloon dataset for training
│
├── src/
│   ├── main/                       # Final working versions
│   │   └── argus_gloveCircuit/argus_gloveCircuit.ino   # Code of ESP32 based gesture controlled glove.
│   │   └── argus_v1_final.py       # Final working version with bidirectional yaw, GPIO fix, camera optimisation
│   ├── test/                       # Isolated test scripts (previous version testing, SITL, UDP)
│   ├── training/                   # Training pipeline code
│   └── versions/                   # Older revisions and experiments
│
├── logs/                           # Gesture + aiming logs (autogenerated)
├── requirements.txt                # Python dependencies
└── README.md                       # Project documentation
```

---

## Features (Implemented)

- **Balloon detection using YOLOv8** trained on custom dataset
- **Center coordinate extraction** with pixel → angle mapping
- **Live servo angle control** via GPIO PWM on Raspberry Pi
- **Laser trigger over GPIO**
- **Drone yaw control** via MAVLink (Pixhawk in Position Hold/Guided mode)
- **UDP-based gesture glove receiver** with killswitch/aim/shoot states
- **PiCamera2 integration** for direct video input on Raspberry Pi
- **Killswitch logic with cooldown** – Prevents accidental unlocks (`Aim`, `Shoot` only after time)
- **Yaw logic: relative to current heading** – Drone now rotates relative to its own orientation, not absolute north  
- **Solid-state relay control** with GPIO library `lgpio` on Raspberry Pi

---

## Getting Started

### 1. Clone the Repository
```bash
git clone git@github.com:sohxm-shah/argus-laser-targeting.git
cd argus-laser-targeting
```

### 2. Install Python Requirements
```bash
pip install -r requirements.txt
```

### 3. Run Final Code (on Raspberry Pi)
```bash
python src/main/argus_v1_final.py
```

Ensure:
- The **Pixhawk** is connected to the Pi (USB or network)
- The **ESP32 glove** is transmitting gestures via UDP to port `4210`
- These values may change depending on your devices, mode of connection (Pixhawk/SITL).
- You have camera and GPIO access
- You have all required libraries installed

---

## Testing Utilities

Found in `src/test/`, these include:
- `set_PosnHold_mode_sitl.py` – Sets SITL drone to Position Hold
- `set_yaw_sitl.py` – Sends MAVLink yaw commands manually
- `udp_receive_on_rpi.py` – Debug UDP gesture packets from glove
- `test_laser_gpio.py` – Minimal script to toggle laser using relay and debug GPIO behavior

---

## YOLOv8 Model Training

Training was done on a dataset of **1250+ balloon images**.  
Use `src/training/train_balloons.py` for re-training. Model weights: `models/argus_model.pt`

---

## Gesture Recognition

Gesture glove transmits over UDP:
- `"Aim"` → Aim laser at detected target
- `"Shoot"` → Fire laser
- `"Killswitch"` → Lock system until next gesture
- *All other gestures* → System Locked

---

## Hardware & Tools

- **Raspberry Pi 5** + PiCamera2
- **Pixhawk 2.4.8** (SITL-tested and real-drone compatible)
- **YOLOv8** (via [Ultralytics](https://github.com/ultralytics/ultralytics))
- **ESP32 Gloves** – Flex sensors for gestures
- **DroneKit / MAVLink** integration
- **Solid State Relay (2-channel, low-level)** for safe laser switching
- **LGPIO Library** for accurate PWM + GPIO on Raspberry Pi

---

## Future Upgrades

- [ ] Full drone flight via second ESP32 glove (pitch/roll via IMU)
- [ ] Laser firing control refinement (PWM duration/safety)
- [ ] Realtime status overlay on detection window
- [ ] OLED screen on glove for feedback
- [ ] `config.py` for centralized parameters

---

## About the Developer

Soham Amit Shah is a first-year Mechanical Engineering student passionate about:
- Aerospace & Defense Technology
- Robotics, Gesture-Based Interfaces and Embedded Systems
- Vision AI and UAV Control Systems